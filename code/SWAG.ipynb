{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5BQQtrwJa3_",
        "outputId": "8788c891-904e-40f7-9192-ece4a871b273"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu769vC9SwYI"
      },
      "source": [
        "# Data Loading and Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.metrics import log_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9WizKlG2CyI",
        "outputId": "5e23212e-d110-474e-c78c-e791fca73c6c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as torchvision_models\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "# Settings and configurations\n",
        "class Config:\n",
        "    dataset = 'CIFAR10'\n",
        "    batch_size = 128\n",
        "    num_workers = 4\n",
        "    model_name = 'resnet18'\n",
        "    pretrained = False\n",
        "    use_test = True\n",
        "    max_num_models = 20\n",
        "    swag_freq = 5  # Collect every 5 epochs\n",
        "    swag_samples = 30\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    epochs = 30\n",
        "\n",
        "# Transforms and DataLoader Initialization for the original CIFAR-10 dataset\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=Config.batch_size, shuffle=True, num_workers=Config.num_workers)\n",
        "testloader = DataLoader(testset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers)\n",
        "\n",
        "# Gaussian blur transformations for the blurred CIFAR-10 datasets\n",
        "blur_transforms = {\n",
        "    'light': transforms.Compose([transforms.GaussianBlur(kernel_size=5, sigma=0.5), transforms.ToTensor()]),\n",
        "    'medium': transforms.Compose([transforms.GaussianBlur(kernel_size=5, sigma=1.0), transforms.ToTensor()]),\n",
        "    'heavy': transforms.Compose([transforms.GaussianBlur(kernel_size=5, sigma=2.0), transforms.ToTensor()])\n",
        "}\n",
        "\n",
        "# Create blurred test datasets\n",
        "blurred_testsets = {\n",
        "    level: torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "    for level, transform in blur_transforms.items()\n",
        "}\n",
        "\n",
        "# Create blurred test loaders\n",
        "blurred_testloaders = {\n",
        "    level: DataLoader(dataset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers)\n",
        "    for level, dataset in blurred_testsets.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "FK9dHPe4ub-K",
        "outputId": "8849b8b6-cf80-42ac-b0ee-a9c6d9c36905"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "\n",
        "# Update indices to select different images for each level\n",
        "images = {\n",
        "    'light': blurred_testsets['light'][1][0],  # Change indices as needed to select different images\n",
        "    'medium': blurred_testsets['medium'][1][0],\n",
        "    'heavy': blurred_testsets['heavy'][1][0]\n",
        "}\n",
        "\n",
        "# Convert tensors to PIL images for displaying (necessary to plot with imshow)\n",
        "to_pil = transforms.ToPILImage()\n",
        "images_to_display = [to_pil(images[level]) for level in ['light', 'medium', 'heavy']]\n",
        "\n",
        "# Plotting the images\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))  # Increased figure size for better visibility\n",
        "labels = ['Light Blur', 'Medium Blur', 'Heavy Blur']\n",
        "for ax, img, lbl in zip(axs, images_to_display, labels):\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(lbl)\n",
        "    ax.axis('off')  # Hide axes for a cleaner presentation\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46BIkWGBS20E"
      },
      "source": [
        "# Final Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "xrB9VdBAB5KJ",
        "outputId": "e1ac1573-d958-48ca-a24a-664cf51e6728"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "\n",
        "# NLL data for each level of blur\n",
        "nll_data = {\n",
        "    'light': [5278.945, 5035.896, 4946.806, 4877.876, 4852.9966, 4840.8584, 4824.736, 4810.1025, 4805.7373, 4790.665],\n",
        "    'medium': [14386.7656, 13127.416, 13192.074, 13053.315, 13112.65, 13117.619, 13095.448, 12958.928, 12940.623, 12880.335],\n",
        "    'heavy': [22223.3809, 21089.822, 20947.29, 20631.832, 20645.37, 20612.05, 20600.916, 20500.283, 20504.84, 20566.967]\n",
        "}\n",
        "ensemble_nll_data = {\n",
        "    'light':[11217.637, 8481.545, 7744.456, 7430.4204, 7169.99, 7007.3984, 6880.3584, 6801.716, 6759.3486, 6695.2607],\n",
        "    'medium': [17614.764, 13934.449, 12869.195, 12515.346, 12208.555, 11846.072, 11704.497, 11490.144, 11473.371, 11502.004],\n",
        "    'heavy': [25728.617, 20754.98, 19538.945, 18991.52, 18703.586, 18198.537, 18055.906, 17842.186, 17878.336, 18000.768]\n",
        "}\n",
        "model_numbers = list(range(1, 11))  # Model numbers from 1 to 10\n",
        "\n",
        "# Assuming 'blurred_testsets' is available with images for each blur level\n",
        "images = {\n",
        "    'light': blurred_testsets['light'][1][0],\n",
        "    'medium': blurred_testsets['medium'][1][0],\n",
        "    'heavy': blurred_testsets['heavy'][1][0]\n",
        "}\n",
        "\n",
        "# Convert tensors to PIL images for displaying\n",
        "to_pil = transforms.ToPILImage()\n",
        "images_to_display = {level: to_pil(images[level]) for level in ['light', 'medium', 'heavy']}\n",
        "\n",
        "# Plotting NLL values and the respective images for each blur level\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))  # Adjust the overall figure size\n",
        "for ax, level in zip(axs, ['light', 'medium', 'heavy']):\n",
        "    ax.plot(model_numbers, nll_data[level], marker='o', linestyle='-', label='Deep Ensembles')\n",
        "    ax.plot(model_numbers, ensemble_nll_data[level], marker='o', linestyle='-', label='Multi Swag')\n",
        "    ax.set_title(f'NLL vs. Number of Models ({level.capitalize()} Corruption)')\n",
        "    ax.set_xlabel('# Models')\n",
        "    ax.set_ylabel('NLL')\n",
        "    ax.grid(True)\n",
        "\n",
        "    # Aspect ratio to make plots more square\n",
        "    ax.set_aspect(aspect='auto', adjustable='box')\n",
        "\n",
        "    # Inset image\n",
        "    inset_ax = ax.inset_axes([0.6, 0.5, 0.30, 0.45])\n",
        "    inset_ax.imshow(images_to_display[level])\n",
        "    inset_ax.set_title(f'{level.capitalize()} Image')\n",
        "    inset_ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "fig.legend(['Deep Ensembles', 'Multi Swag'], loc='lower center', ncol=2, borderaxespad=0.5, frameon=False)\n",
        "plt.subplots_adjust(bottom=0.2)  # Adjust the bottom margin to make room for the legend\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kYEtKkvNE1M"
      },
      "source": [
        "## Stochastic Weight Averaging-Gaussian (SWAG) Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "a71dllkmRz5f",
        "outputId": "95308904-e446-4625-f74d-98179ab7e70b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as torchvision_models\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Settings and configurations\n",
        "class Config:\n",
        "    dataset = 'CIFAR10'\n",
        "    batch_size = 100\n",
        "    num_workers = 4\n",
        "    model_name = 'resnet18'\n",
        "    pretrained = False\n",
        "    use_test = True\n",
        "    max_num_models = 5  # Maximum models to collect\n",
        "    swag_freq = 5  # Frequency of collection per epoch\n",
        "    swag_samples = [5, 3, 1]  # Models to use for testing\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    epochs = 20  # Total epochs to collect enough models\n",
        "\n",
        "# Transforms and DataLoader Initialization\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=Config.batch_size, shuffle=True, num_workers=Config.num_workers)\n",
        "testloader = DataLoader(testset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers)\n",
        "\n",
        "# Gaussian blur transformations for the blurred CIFAR-10 datasets\n",
        "blur_transforms = {\n",
        "    'light': transforms.Compose([transforms.GaussianBlur(kernel_size=5, sigma=0.5), transforms.ToTensor()]),\n",
        "    'medium': transforms.Compose([transforms.GaussianBlur(kernel_size=5, sigma=1.0), transforms.ToTensor()]),\n",
        "    'heavy': transforms.Compose([transforms.GaussianBlur(kernel_size=5, sigma=2.0), transforms.ToTensor()])\n",
        "}\n",
        "blurred_testsets = {\n",
        "    level: torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "    for level, transform in blur_transforms.items()\n",
        "}\n",
        "blurred_testloaders = {\n",
        "    level: DataLoader(dataset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers)\n",
        "    for level, dataset in blurred_testsets.items()\n",
        "}\n",
        "\n",
        "# Training and Evaluation Functions\n",
        "def train_epoch(loader, model, criterion, optimizer, device, swag_model=None, collect=False, epoch=None):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total_batches = len(loader)\n",
        "    for i, (inputs, targets) in enumerate(loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss, outputs, _ = criterion(model, inputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f'Epoch {epoch}, Batch {i + 1}/{total_batches}, Loss: {running_loss / (i + 1):.4f}')\n",
        "\n",
        "        if collect and (i + 1) % Config.swag_freq == 0:\n",
        "            swag_model.collect_model(model)\n",
        "            if swag_model.n_models.item() == Config.max_num_models:\n",
        "                break  # Stop collecting after max models reached\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    accuracy = 100. * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Plotting function\n",
        "def plot_accuracies(acc_results):\n",
        "    fig, ax = plt.subplots()\n",
        "    for level in ['light', 'medium', 'heavy']:\n",
        "        models = sorted(acc_results[level].keys())\n",
        "        accuracies = [acc_results[level][model] for model in models]\n",
        "        ax.plot(models, accuracies, marker='o', label=f'{level} blur')\n",
        "\n",
        "    ax.set_xlabel('Number of Models')\n",
        "    ax.set_ylabel('Accuracy (%)')\n",
        "    ax.set_title('Model Accuracy by Blur Level and Number of Models')\n",
        "    ax.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Main Execution Logic\n",
        "def main():\n",
        "    model = torchvision_models.__dict__[Config.model_name](pretrained=Config.pretrained)\n",
        "    model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "    model.to(Config.device)\n",
        "\n",
        "    swag_model = SWAG(model)\n",
        "    swag_model.to(Config.device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(base_model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "    # Training and collecting models\n",
        "    print(\"Starting training and model collection...\")\n",
        "    for epoch in range(Config.epochs):\n",
        "        train_epoch(trainloader, model, criterion, optimizer, Config.device, swag_model, collect=True, epoch=epoch+1)\n",
        "        if swag_model.n_models.item() == Config.max_num_models:\n",
        "            break\n",
        "\n",
        "    # Evaluating SWAG model on different numbers of collected models\n",
        "    acc_results = {level: {} for level in ['light', 'medium', 'heavy']}\n",
        "    for num_models in Config.swag_samples:\n",
        "        swag_model.reset()\n",
        "        print(f\"Evaluating with {num_models} models...\")\n",
        "        for level, loader in blurred_testloaders.items():\n",
        "            swag_model.sample(scale=0.5)\n",
        "            accuracy = evaluate(swag_model, loader, Config.device)\n",
        "            acc_results[level][num_models] = accuracy\n",
        "            print(f\"{level.capitalize()} Blur, {num_models} Models: {accuracy:.2f}% Accuracy\")\n",
        "\n",
        "    plot_accuracies(acc_results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt0xJdzBNV-G"
      },
      "source": [
        "## SWAG Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvJ17DSaAX4S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import itertools\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def save_checkpoint(dir, epoch, name='checkpoint', **kwargs):\n",
        "    state = {'epoch': epoch}\n",
        "    state.update(kwargs)\n",
        "    filepath = os.path.join(dir, f'{name}-{epoch}.pt')\n",
        "    torch.save(state, filepath)\n",
        "\n",
        "def set_weights(model, vector, device=None):\n",
        "    offset = 0\n",
        "    for param in model.parameters():\n",
        "        param.data.copy_(vector[offset:offset + param.numel()].view(param.size()).to(device))\n",
        "        offset += param.numel()\n",
        "\n",
        "def nll(outputs, labels):\n",
        "    labels = labels.astype(int)\n",
        "    idx = (np.arange(labels.size), labels)\n",
        "    ps = outputs[idx]\n",
        "    return -np.sum(np.log(ps))\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    return (np.argmax(outputs, axis=1) == labels).mean()\n",
        "\n",
        "def compute_loss_and_stats(loader, model, criterion, cuda=True, regression=False, regularizer=None, train_mode=True, optimizer=None):\n",
        "    loss_sum = 0.0\n",
        "    correct = 0.0\n",
        "    stats_sum = defaultdict(float)\n",
        "    num_objects_total = 0\n",
        "\n",
        "    model.train(train_mode)\n",
        "    with torch.set_grad_enabled(train_mode):\n",
        "        for input, target in loader:\n",
        "            if cuda:\n",
        "                input = input.cuda(non_blocking=True)\n",
        "                target = target.cuda(non_blocking=True)\n",
        "\n",
        "            loss, output, stats = criterion(model, input, target)\n",
        "            if regularizer and train_mode:\n",
        "                loss += regularizer(model)\n",
        "\n",
        "            if train_mode and optimizer:\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            loss_sum += loss.item() * input.size(0)\n",
        "            for key, value in stats.items():\n",
        "                stats_sum[key] += value * input.size(0)\n",
        "\n",
        "            if not regression:\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "            num_objects_total += input.size(0)\n",
        "\n",
        "    return loss_sum, correct, stats_sum, num_objects_total\n",
        "\n",
        "def train_epoch(loader, model, criterion, optimizer, cuda=True, regression=False, verbose=False, subset=None, regularizer=None):\n",
        "    num_batches = len(loader)\n",
        "    if subset is not None:\n",
        "        num_batches = int(len(loader) * subset)\n",
        "        loader = itertools.islice(loader, num_batches)\n",
        "\n",
        "    if verbose:\n",
        "        loader = tqdm.tqdm(loader, total=num_batches)\n",
        "\n",
        "    loss_sum, correct, stats_sum, num_objects_total = compute_loss_and_stats(\n",
        "        loader, model, criterion, cuda, regression, regularizer, train_mode=True, optimizer=optimizer\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'loss': loss_sum / num_objects_total,\n",
        "        'accuracy': None if regression else correct / num_objects_total * 100.0,\n",
        "        'stats': {key: value / num_objects_total for key, value in stats_sum.items()}\n",
        "    }\n",
        "\n",
        "def eval(loader, model, criterion, cuda=True, regression=False, verbose=False):\n",
        "    if verbose:\n",
        "        loader = tqdm.tqdm(loader)\n",
        "\n",
        "    loss_sum, correct, stats_sum, num_objects_total = compute_loss_and_stats(\n",
        "        loader, model, criterion, cuda, regression, train_mode=False\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'loss': loss_sum / num_objects_total,\n",
        "        'accuracy': None if regression else correct / num_objects_total * 100.0,\n",
        "        'stats': {key: value / num_objects_total for key, value in stats_sum.items()}\n",
        "    }\n",
        "\n",
        "def predict(loader, model, verbose=False):\n",
        "    predictions, targets = [], []\n",
        "    model.eval()\n",
        "\n",
        "    if verbose:\n",
        "        loader = tqdm.tqdm(loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input, target in loader:\n",
        "            input = input.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            target = target.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            output = model(input)\n",
        "            predictions.append(F.softmax(output, dim=1).cpu().numpy())\n",
        "            targets.append(target.cpu().numpy())\n",
        "\n",
        "    return {\n",
        "        'predictions': np.vstack(predictions),\n",
        "        'targets': np.concatenate(targets)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vxmaffm55YDn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import itertools\n",
        "import tqdm\n",
        "\n",
        "def bn_update(loader, model, verbose=False, subset=None, **kwargs):\n",
        "    flag = [False]\n",
        "    model.apply(lambda module: flag.__setitem__(0, True) if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm) else None)\n",
        "    if not flag[0]:\n",
        "        return\n",
        "\n",
        "    model.train()\n",
        "    momenta = {}\n",
        "\n",
        "    model.apply(lambda module: [setattr(module, 'running_mean', torch.zeros_like(module.running_mean)) or setattr(module, 'running_var', torch.ones_like(module.running_var)) if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm) else None])\n",
        "\n",
        "    model.apply(lambda module: momenta.__setitem__(module, module.momentum) if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm) else None)\n",
        "\n",
        "    n = 0\n",
        "    num_batches = len(loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if subset is not None:\n",
        "            num_batches = int(num_batches * subset)\n",
        "            loader = itertools.islice(loader, num_batches)\n",
        "        if verbose:\n",
        "            loader = tqdm.tqdm(loader, total=num_batches)\n",
        "\n",
        "        for input, _ in loader:\n",
        "            input = input.cuda(non_blocking=True)\n",
        "            input_var = torch.autograd.Variable(input)\n",
        "            b = input_var.data.size(0)\n",
        "\n",
        "            momentum = b / (n + b)\n",
        "            for module in momenta.keys():\n",
        "                module.momentum = momentum\n",
        "\n",
        "            model(input_var, **kwargs)\n",
        "            n += b\n",
        "\n",
        "    # Restore original momenta for all batch norm layers\n",
        "    model.apply(lambda module: setattr(module, 'momentum', momenta[module]) if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm) else None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I09qy20tNj86"
      },
      "source": [
        "## Stochastic Weight Averaging-Gaussian (SWAG) Implmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPnT9FvVdXVT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SWAG(nn.Module):\n",
        "    def __init__(self, base_model, variance_clamp=1e-6, max_rank=20):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.num_parameters = sum(p.numel() for p in base_model.parameters())\n",
        "        self.max_rank = max_rank\n",
        "        self.variance_clamp = variance_clamp\n",
        "        self.model_device = torch.device('cpu')  # Use CPU for Mac\n",
        "\n",
        "        self.register_buffer('mean', torch.zeros(self.num_parameters))  \n",
        "        self.register_buffer('square_mean', torch.zeros(self.num_parameters))  \n",
        "        self.register_buffer('num_collected_models', torch.zeros(1, dtype=torch.long))\n",
        "        self.register_buffer('rank', torch.zeros(1, dtype=torch.long))\n",
        "        self.register_buffer('cov_mat_sqrt', torch.empty(0, self.num_parameters, dtype=torch.float32))\n",
        "        self.covariance_factor = None\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        return self.base_model(*args, **kwargs)\n",
        "\n",
        "    def collect_model(self, model_instance):\n",
        "        flat_params = torch.cat([p.detach().cpu().view(-1) for p in model_instance.parameters()])\n",
        "        num_collected = self.num_collected_models.item() + 1\n",
        "\n",
        "        self.mean = (self.mean * ((num_collected - 1) / num_collected)) + (flat_params / num_collected)\n",
        "        self.square_mean = (self.square_mean * ((num_collected - 1) / num_collected)) + (flat_params.pow(2) / num_collected)\n",
        "\n",
        "        if self.rank.item() >= self.max_rank:\n",
        "            self.cov_mat_sqrt = self.cov_mat_sqrt[1:]\n",
        "        self.cov_mat_sqrt = torch.cat((self.cov_mat_sqrt, (flat_params - self.mean).unsqueeze(0)), dim=0)\n",
        "        self.rank = torch.clamp(self.rank + 1, max=self.max_rank)\n",
        "        self.num_collected_models += 1\n",
        "\n",
        "    def _get_mean_and_variance(self):\n",
        "        variance = torch.clamp(self.square_mean - self.mean.pow(2), self.variance_clamp)\n",
        "        return self.mean, variance\n",
        "\n",
        "    def fit(self):\n",
        "        if self.covariance_factor is None:\n",
        "            self.covariance_factor = self.cov_mat_sqrt.clone() / (self.cov_mat_sqrt.size(0) - 1) ** 0.5\n",
        "\n",
        "    def set_swa(self):\n",
        "        self._set_weights(self.mean)\n",
        "\n",
        "    def sample(self, scale=0.5, diagonal_noise=True):\n",
        "        self.fit()\n",
        "        mean, variance = self._get_mean_and_variance()\n",
        "        low_rank_noise = torch.randn(self.covariance_factor.size(0), device=self.model_device)\n",
        "        scaled_noise = self.covariance_factor.t().matmul(low_rank_noise)\n",
        "\n",
        "        if diagonal_noise:\n",
        "            scaled_noise += variance.sqrt() * torch.randn_like(variance)\n",
        "\n",
        "        self._set_weights(mean + scaled_noise * scale.sqrt())\n",
        "        return mean + scaled_noise * scale.sqrt()\n",
        "\n",
        "    def _set_weights(self, weights):\n",
        "        offset = 0\n",
        "        for param in self.base_model.parameters():\n",
        "            param_length = param.numel()\n",
        "            param.data.copy_(weights[offset:offset + param_length].view(param.size()))\n",
        "            offset += param_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have created a simple test to check to see if SWAG is working. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1vbE20pTKum"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import pandas as pd\n",
        "import time\n",
        "from collections import defaultdict\n",
        "\n",
        "def simple_criterion(model, input, target):\n",
        "    output = model(input)\n",
        "    loss = nn.CrossEntropyLoss()(output, target)\n",
        "    stats = {}  \n",
        "    return loss, output, stats\n",
        "\n",
        "def train_swag_test():\n",
        "    class Config:\n",
        "        dataset = 'CIFAR10'\n",
        "        batch_size = 64\n",
        "        num_workers = 2\n",
        "        model_name = 'SimpleNN'\n",
        "        use_test = True\n",
        "        max_num_models = 3\n",
        "        swag_freq = 5\n",
        "        save_freq = 10\n",
        "        swag_samples = 5\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        epochs = 5\n",
        "        swag_start = 3\n",
        "        lr_init = 0.01\n",
        "        momentum = 0.9\n",
        "        wd = 1e-4\n",
        "        eval_freq = 2\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    small_trainset = Subset(trainset, range(50))  \n",
        "    small_testset = Subset(testset, range(10))   \n",
        "\n",
        "    trainloader = DataLoader(small_trainset, batch_size=Config.batch_size, shuffle=True, num_workers=Config.num_workers)\n",
        "    testloader = DataLoader(small_testset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers)\n",
        "\n",
        "    base_model = torchvision.models.resnet18(pretrained=False)\n",
        "    base_model.fc = nn.Linear(base_model.fc.in_features, 10)  \n",
        "    base_model.to(Config.device)\n",
        "\n",
        "    swag_model = SWAG(base_model, max_rank=Config.max_num_models)\n",
        "    swag_model.to(Config.device)\n",
        "\n",
        "    optimizer = optim.SGD(base_model.parameters(), lr=Config.lr_init, momentum=Config.momentum, weight_decay=Config.wd)\n",
        "    criterion = simple_criterion\n",
        "\n",
        "    def eval(loader, model, criterion):\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in loader:\n",
        "                inputs, targets = inputs.to(Config.device), targets.to(Config.device)\n",
        "                loss, outputs, stats = criterion(model, inputs, targets)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "        return running_loss / total, 100. * correct / total\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for epoch in range(Config.epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        train_result = train_epoch(trainloader, base_model, criterion, optimizer, cuda=Config.device.type=='cuda')\n",
        "        train_loss, train_acc = train_result['loss'], train_result['accuracy']\n",
        "        test_loss, test_acc = eval(testloader, base_model, criterion)\n",
        "\n",
        "        swag_loss, swag_acc = None, None\n",
        "        if (epoch + 1) >= Config.swag_start:\n",
        "            swag_model.collect_model(base_model)\n",
        "\n",
        "            if epoch % Config.eval_freq == 0 or epoch == Config.epochs - 1:\n",
        "                swag_model.set_swa()\n",
        "                swag_loss, swag_acc = eval(testloader, swag_model, criterion)\n",
        "                print(f'SWAG Evaluation - Epoch: {epoch + 1}, Loss: {swag_loss:.4f}, Accuracy: {swag_acc:.2f}%')\n",
        "\n",
        "        epoch_duration = time.time() - epoch_start_time\n",
        "        results.append([\n",
        "            epoch + 1,\n",
        "            train_loss,\n",
        "            train_acc,\n",
        "            test_loss,\n",
        "            test_acc,\n",
        "            swag_loss,\n",
        "            swag_acc,\n",
        "            epoch_duration\n",
        "        ])\n",
        "\n",
        "    results_df = pd.DataFrame(results, columns=['Epoch', 'Train Loss', 'Train Acc', 'Test Loss', 'Test Acc', 'SWAG Loss', 'SWAG Acc', 'Time'])\n",
        "\n",
        "    print(\"SWAG training and testing complete.\")\n",
        "    return results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "r9ySZz5QaGI5",
        "outputId": "698902b8-9c6e-409f-a6b6-3cf35072c99a"
      },
      "outputs": [],
      "source": [
        "results_df = train_swag_test()\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttOkTmT6Np0_"
      },
      "source": [
        "### Training the SWAG models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-W7SVBUMrHCB"
      },
      "outputs": [],
      "source": [
        "import tabulate\n",
        "\n",
        "def train_swag(ckpt_directory):\n",
        "    class Config:\n",
        "        dataset = 'CIFAR10'\n",
        "        batch_size = 100\n",
        "        num_workers = 4\n",
        "        model_name = 'resnet18'\n",
        "        pretrained = False\n",
        "        use_test = True\n",
        "        max_num_models = 5  # Maximum models to collect\n",
        "        swag_freq = 5  # Frequency of collection per epoch\n",
        "        save_freq = 10  # Frequency of collection per epoch\n",
        "        swag_samples = 15  # Models to use for testing\n",
        "        # device = torch.device('cpu')\n",
        "        epochs = 40  # Total epochs to collect enough models\n",
        "        swag_start = 20\n",
        "        lr_init = 0.1  # Initial learning rate\n",
        "        momentum = 0.9  # Momentum for SGD\n",
        "        wd = 5e-4  # Weight decay for SGD\n",
        "        eval_freq = 5\n",
        "        dir = ckpt_directory\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Transforms and DataLoader Initialization\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    print('Loading dataset %s' % Config.dataset)\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "    trainloader = DataLoader(trainset, batch_size=Config.batch_size, shuffle=True, num_workers=Config.num_workers)\n",
        "    testloader = DataLoader(testset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers)\n",
        "\n",
        "    print('Using model %s' % Config.model_name)\n",
        "\n",
        "    print('Preparing directory %s' % Config.dir)\n",
        "    os.makedirs(Config.dir, exist_ok=True)\n",
        "    with open(os.path.join(Config.dir, 'command.sh'), 'w') as f:\n",
        "        f.write(' '.join(sys.argv))\n",
        "        f.write('\\n')\n",
        "    print('Preparing model')\n",
        "\n",
        "    base_model = models.resnet18(pretrained=Config.pretrained)\n",
        "    base_model.fc = nn.Linear(base_model.fc.in_features, 10)  # Adjust for CIFAR-10\n",
        "    base_model.to(Config.device)\n",
        "\n",
        "    print('SWAG training')\n",
        "    # SWAG Model Initialization\n",
        "    swag_model = SWAG(base_model, max_rank=Config.max_num_models)\n",
        "    swag_model.to(Config.device)\n",
        "\n",
        "    optimizer = optim.SGD(base_model.parameters(), lr=Config.lr_init, momentum=Config.momentum, weight_decay=Config.wd)\n",
        "\n",
        "    def cross_entropy_loss(model, inputs, targets):\n",
        "        outputs = model(inputs)\n",
        "        loss = nn.functional.cross_entropy(outputs, targets)\n",
        "        return loss, outputs, {}\n",
        "\n",
        "    criterion = cross_entropy_loss\n",
        "\n",
        "    num_ensembled_models = 0.0\n",
        "\n",
        "    columns = ['Epoch', 'LR', 'Train Loss', 'Train Acc', 'Test Loss', 'Test Acc', 'Time']\n",
        "\n",
        "    for epoch in range(0, Config.epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        print()\n",
        "\n",
        "        train_results = train_epoch(trainloader, base_model, criterion, optimizer, regularizer=None)\n",
        "\n",
        "        if epoch == 0 or epoch % Config.eval_freq == Config.eval_freq - 1 or epoch == Config.epochs - 1:\n",
        "            test_results = eval(trainloader, base_model, criterion,Config.device)\n",
        "        else:\n",
        "            test_results = {'loss': None, 'accuracy': None}\n",
        "\n",
        "        if (epoch + 1) > Config.swag_start:\n",
        "            swag_model.collect_model(base_model)\n",
        "\n",
        "            if epoch == 0 or epoch % Config.eval_freq == Config.eval_freq - 1 or epoch == Config.epochs - 1:\n",
        "                swag_model.set_swa()\n",
        "                bn_update(trainloader, swag_model)\n",
        "                swag_results = eval(testloader, swag_model, criterion)\n",
        "\n",
        "        if (epoch + 1) % Config.save_freq == 0:\n",
        "            save_checkpoint(\n",
        "                Config.dir,\n",
        "                epoch + 1,\n",
        "                state_dict=base_model.state_dict(),\n",
        "                optimizer=optimizer.state_dict()\n",
        "            )\n",
        "            save_checkpoint(\n",
        "                Config.dir,\n",
        "                epoch + 1,\n",
        "                name='swag',\n",
        "                state_dict=swag_model.state_dict(),\n",
        "            )\n",
        "\n",
        "        epoch_duration = time.time() - epoch_start_time\n",
        "        epoch_stats = [\n",
        "            epoch + 1,\n",
        "            Config.lr_init,\n",
        "            train_results['loss'],\n",
        "            train_results['accuracy'],\n",
        "            test_results['loss'],\n",
        "            test_results['accuracy'],\n",
        "            epoch_duration\n",
        "        ]\n",
        "\n",
        "        epoch_table = tabulate.tabulate(\n",
        "            [epoch_stats], columns, tablefmt='simple', floatfmt='8.4f'\n",
        "        )\n",
        "        if epoch % 10 == 0:\n",
        "            epoch_table = epoch_table.split('\\n')\n",
        "            epoch_table = '\\n'.join([epoch_table[1]] + epoch_table)\n",
        "        else:\n",
        "            epoch_table = epoch_table.split('\\n')[2]\n",
        "        print(epoch_table)\n",
        "\n",
        "    if Config.epochs % Config.save_freq != 0:\n",
        "        save_checkpoint(\n",
        "            Config.dir,\n",
        "            Config.epochs,\n",
        "            state_dict=base_model.state_dict(),\n",
        "            optimizer=optimizer.state_dict()\n",
        "        )\n",
        "        if Config.epochs > Config.swag_start:\n",
        "            save_checkpoint(\n",
        "                Config.dir,\n",
        "                Config.epochs,\n",
        "                name='swag',\n",
        "                state_dict=swag_model.state_dict(),\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "EcYbqkcJJFzy",
        "outputId": "a6ebab6d-18ac-480a-dec7-e75c2b2803b4"
      },
      "outputs": [],
      "source": [
        "for i in range(11):\n",
        "  train_swag(f\"ckpts/swag_{i}_correct\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNvJbn1qUisf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import tabulate\n",
        "\n",
        "def eval_swag(trainloader, testloader, swag_checkpoints, save_directory):\n",
        "    class Config:\n",
        "        dataset = 'CIFAR10'\n",
        "        batch_size = 100\n",
        "        num_workers = 4\n",
        "        model_name = 'resnet18'\n",
        "        pretrained = False\n",
        "        use_test = True\n",
        "        swag_freq = 5\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        epochs = 20\n",
        "        swag_ckpts = swag_checkpoints\n",
        "        savedir = save_directory\n",
        "        swag_samples = 10\n",
        "\n",
        "    print('Preparing model')\n",
        "    base_model = models.resnet18(pretrained=Config.pretrained)\n",
        "    base_model.fc = nn.Linear(base_model.fc.in_features, 10)  # Adjust for CIFAR-10\n",
        "    base_model.to(Config.device)\n",
        "\n",
        "    print('SWAG evaluation')\n",
        "    # SWAG Model Initialization\n",
        "    swag_model = SWAG(base_model)\n",
        "    swag_model.to(Config.device)\n",
        "\n",
        "    print(\"Model has {} parameters\".format(\n",
        "        sum(param.numel() for param in base_model.parameters())))\n",
        "\n",
        "    columns = ['SWAG', 'Sample', 'Test Loss', 'Test Acc', 'Ens Loss', 'Ens Acc']\n",
        "\n",
        "    num_ensembled_models = 0.0\n",
        "    multiswag_probabilities = None\n",
        "    ensemble_nll_list = []\n",
        "\n",
        "    for checkpoint_index, checkpoint_path in enumerate(Config.swag_ckpts):\n",
        "        print(\"Checkpoint {}\".format(checkpoint_path))\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        swag_model.load_state_dict(checkpoint['state_dict'])\n",
        "        print('Number of ensembled models: ', num_ensembled_models)\n",
        "\n",
        "        for sample_index in range(Config.swag_samples):\n",
        "            swag_model.sample(0.5)\n",
        "            bn_update(trainloader, swag_model)\n",
        "            evaluation_results = predict(testloader, swag_model)\n",
        "            probabilities = evaluation_results['predictions']\n",
        "            targets = evaluation_results['targets']\n",
        "            nll_value = nll(probabilities, targets)\n",
        "            accuracy_value = accuracy(probabilities, targets)\n",
        "\n",
        "            if multiswag_probabilities is None:\n",
        "                multiswag_probabilities = probabilities.copy()\n",
        "            else:\n",
        "                multiswag_probabilities += (probabilities - multiswag_probabilities) / (num_ensembled_models + 1)\n",
        "\n",
        "            num_ensembled_models += 1\n",
        "\n",
        "            ensemble_nll = nll(multiswag_probabilities, targets)\n",
        "            ensemble_accuracy = accuracy(multiswag_probabilities, targets)\n",
        "            epoch_stats = [\n",
        "                checkpoint_index,\n",
        "                sample_index,\n",
        "                nll_value,\n",
        "                accuracy_value,\n",
        "                ensemble_nll,\n",
        "                ensemble_accuracy\n",
        "            ]\n",
        "\n",
        "            epoch_table = tabulate.tabulate(\n",
        "                [epoch_stats], columns, tablefmt='simple', floatfmt='8.4f'\n",
        "            )\n",
        "            print(epoch_table)\n",
        "\n",
        "        ensemble_nll_list.append(ensemble_nll)\n",
        "\n",
        "    print('Preparing directory %s' % Config.savedir)\n",
        "    os.makedirs(Config.savedir, exist_ok=True)\n",
        "    with open(os.path.join(Config.savedir, 'eval_command.sh'), 'w') as f:\n",
        "        f.write(' '.join(sys.argv))\n",
        "        f.write('\\n')\n",
        "\n",
        "    np.savez(os.path.join(Config.savedir, \"multiswag_probs.npz\"),\n",
        "             predictions=multiswag_probabilities,\n",
        "             targets=targets)\n",
        "\n",
        "    return ensemble_nll_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DFcPZp4udz4T"
      },
      "outputs": [],
      "source": [
        "# Transforms and DataLoader Initialization\n",
        "%cd \"/content/drive/MyDrive/4782\"\n",
        "\n",
        "class Config:\n",
        "    dataset = 'CIFAR10'\n",
        "    batch_size = 100\n",
        "    num_workers = 4\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=Config.batch_size, shuffle=True, num_workers=Config.num_workers)\n",
        "testloader = DataLoader(testset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers)\n",
        "\n",
        "# Gaussian blur transformations for the blurred CIFAR-10 datasets\n",
        "blur_transforms = {\n",
        "    'light': transforms.Compose([transforms.GaussianBlur(kernel_size=5, sigma=0.5), transforms.ToTensor()]),\n",
        "    'medium': transforms.Compose([transforms.GaussianBlur(kernel_size=5, sigma=1.0), transforms.ToTensor()]),\n",
        "    'heavy': transforms.Compose([transforms.GaussianBlur(kernel_size=5, sigma=2.0), transforms.ToTensor()])\n",
        "}\n",
        "blurred_testsets = {\n",
        "    level: torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "    for level, transform in blur_transforms.items()\n",
        "}\n",
        "blurred_testloaders = {\n",
        "    level: DataLoader(dataset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers)\n",
        "    for level, dataset in blurred_testsets.items()\n",
        "}\n",
        "\n",
        "\n",
        "for level, loader in blurred_testloaders.items():\n",
        "\n",
        "    ens_nll_list = eval_swag(trainloader, loader,['ckpts/swag_1_correct/swag-40.pt', 'ckpts/swag_2_correct/swag-40.pt', 'ckpts/swag_3_correct/swag-40.pt',\n",
        "                                                  'ckpts/swag_4_correct/swag-40.pt', 'ckpts/swag_5_correct/swag-40.pt', 'ckpts/swag_6_correct/swag-40.pt',\n",
        "                                                  'ckpts/swag_7_correct/swag-40.pt', 'ckpts/swag_8_correct/swag-40.pt', 'ckpts/swag_9_correct/swag-40.pt',\n",
        "                                                  'ckpts/swag_10_correct/swag-40.pt'],\n",
        "                             \"ckpts/eval\" )\n",
        "    print(f\"nll at level: {level}, {ens_nll_list})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkb6JSKKYyk3",
        "outputId": "648ebe58-a341-473e-8b24-50349ef0b36b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "class Config:\n",
        "    dataset = 'CIFAR10'\n",
        "    batch_size = 128\n",
        "    epochs = 10\n",
        "    num_models = 10\n",
        "    lr = 0.01\n",
        "    momentum = 0.9\n",
        "    weight_decay = 1e-4\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=Config.batch_size, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=Config.batch_size, shuffle=False)\n",
        "\n",
        "blur_transforms = {\n",
        "    'light': transforms.Compose([transforms.GaussianBlur(kernel_size=5, sigma=0.5), transform]),\n",
        "    'medium': transforms.Compose([transforms.GaussianBlur(kernel_size=5, sigma=1.0), transform]),\n",
        "    'heavy': transforms.Compose([transforms.GaussianBlur(kernel_size=5, sigma=2.0), transform])\n",
        "}\n",
        "\n",
        "blurred_testloaders = {\n",
        "    level: DataLoader(torchvision.datasets.CIFAR10(root='./data', train=False, download=True,\n",
        "                                                  transform=blur_transforms[level]),\n",
        "                      batch_size=Config.batch_size, shuffle=False)\n",
        "    for level in ['light', 'medium', 'heavy']\n",
        "}\n",
        "\n",
        "def nll(outputs, labels):\n",
        "    labels = labels.astype(int)\n",
        "    idx = (np.arange(labels.size), labels)\n",
        "    ps = outputs[idx]\n",
        "    nll = -np.sum(np.log(ps))\n",
        "    return nll\n",
        "\n",
        "def train_model(model_number):\n",
        "    model = models.resnet18(pretrained=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "    model.to(Config.device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=Config.lr, momentum=Config.momentum, weight_decay=Config.weight_decay)\n",
        "    for epoch in range(Config.epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(trainloader, 1):\n",
        "            inputs, labels = inputs.to(Config.device), labels.to(Config.device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Model {model_number}, Epoch {epoch+1}/{Config.epochs}, Average Loss: {running_loss / i:.4f}\")\n",
        "    return model\n",
        "\n",
        "def evaluate_ensemble(models_ensemble, loader, level):\n",
        "    ensemble_probs = []\n",
        "    targets = []\n",
        "    for index, model in enumerate(models_ensemble, start=1):\n",
        "        model.eval()\n",
        "        all_probs = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in loader:\n",
        "                inputs = inputs.to(Config.device)\n",
        "                outputs = model(inputs)\n",
        "                probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "                all_probs.extend(probabilities.cpu().numpy())\n",
        "                if index == 1:  # Collect targets only once\n",
        "                    targets.extend(labels.cpu().numpy())\n",
        "        ensemble_probs.append(all_probs)\n",
        "    ensemble_probs = np.mean(np.array(ensemble_probs), axis=0)\n",
        "    nll = log_loss(targets, ensemble_probs, labels=list(range(10)))\n",
        "    print(f\"Evaluating {level} blur with {len(models_ensemble)} models: NLL = {nll:.4f}\")\n",
        "    return nll\n",
        "\n",
        "models_ensemble = []\n",
        "nll_scores = {level: [] for level in ['light', 'medium', 'heavy']}\n",
        "\n",
        "for i in range(1, Config.num_models + 1):\n",
        "    print(f\"Training model {i}/{Config.num_models}\")\n",
        "    model = train_model(i)\n",
        "    models_ensemble.append(model)\n",
        "\n",
        "    for level, loader in blurred_testloaders.items():\n",
        "        nll = evaluate_ensemble(models_ensemble, loader, level)\n",
        "        nll_scores[level].append(nll)\n",
        "        print(f\"Current NLL for {level} blur after adding model {i}: {nll_scores[level][-1]:.4f}\")\n",
        "        print(f\"Accumulated NLL scores for {level} blur: {nll_scores[level]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
